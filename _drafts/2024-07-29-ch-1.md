---
layout: post
title: "Chapter 1: Backtesting and Automated Execution"
tags: [Notes: Algorithmic Trading By Ernest Chan]
---
## Chapter 1: Backtesting and Automated Execution
**Disclaimer:** Filled with god-awful typos / nasty run-ons / incomplete sentences! For personal use, proceed with caution! 

Source Material


---
### The importance of backtesting

Definition: Backtesting
Backtesting is the process of feeding historical data to your trading strategy to see how it would perform. 

We use backtesting to not only test our own strategies but also test others and pinpoint details missed by researchers. Ideally, we would implement these into our own automated execution by transforming our backtesting system. 

Backtesting a published strategy allows you to conduct true out-of-sample testing in the period following the publication without data warping. 

Once we implement every detail of a strategy as a backtesting program, we can put them through a microscope and look for pitfalls in the backtesting process or in the strategy itself. 

### Common pitfalls of backtesting 

**Look-ahead bias**
Definition: Look ahead bias 
This bias means you backtest using future prices to determine today's trading signals. More generally, future information is testing data. 
- programming error that can infect backtest program and live trading program
- if backtesting and live trading programs are one of the same, only difference is the data fed in (historical vs live) there can be no look-ahead bias in the program 

entry signal: indicator for optimal entry of trade 

### Data snooping bias and beauty of linearity 

**Data snooping:**
caused by having too many free parameters that are fitted to random ethereal market patterns in the past to make historical performance look good 
- random market patterns unlikely to reoccur in future
- model fit to these patterns is unlikely to have much predictive power
- Mystical Overfitting

**To detect data snooping:**
Test the model on out-of-sample data and reject the model that doesn't pass the tests. Tweaking the out-of-sample data turns it into in-sample data. Don't be a dweeb and do that. 

**Cross validation:**
Instead of tweaking the model and using cherry picked data, use cross validation. Select a number of different subsets of data for training and tweak the model accordingly.
- make sure the model performs well on the different subsets

We prefer models with high sharpe ratios and short max drawdown durations is that it almost automatically ensures the model will pass the cross-validation test: only subsets where the model will fail the test are those with rare downturn periods. 

**sharpe ratio:**
Risk-adjusted return 
$$\text{Sharpe Ratio} = \frac{R_i - R_f}{\sigma_i}$$
- $R_i$: return of investment
- $R_f$: risk free rate
- $\sigma_i$: std. dev of returns (volatility)


**drawdown duration:** 
Reduction of value from peak to trough 
$$\text{Drawdown} = \frac{\text{Peak Value} - \text{Trough value}}{\text{Peak Value}}$$

**General approach**:
Make the model as simple as possible can minimize snooping boas. A model with few parameters but lots of complicated trading rules is just as susceptible to bias (as well as non-linear models).  

Example: If we want to predict price by simple extrapolation of the historical price series, a nonlinear model would fit the historical data better but there is no guarantee it can predict a future value better. Just because the number of parameters are the same for both types of models, they are not the same. 

Kerotsis:
measure if data is heavy-tailed or light-tailed relative to normal dist. 

pareto distribution: 
80/20 rule states that 80% of outcomes are due to 20% of causes. 

**Occam's razor:**
Philosophical problem-solving principle that recommends searching for explanations constructed with the smallest possible set of elements. 

Occam's razor dictates that unless there are strong theoretical and empirical reasons to suppose non-gaussian distributions, the Gaussian form should be assumed. 

Linear formulas $\rightarrow$ linear capital allocation formula



**Capital allocation formula**:
CAL is a graph created by investors to measure the risk of risky and risk-free assets. Its slope is also known as the *reward-to-variability ratio*. 

$$CAL: E(r_c) = r_F + \sigma_C\frac{E(r_P)-r_F}{\sigma_P}$$
P is the risk portfolio, F is the riskless portfolio and C is the combination. 
Interpretation: incremental return of the portfolio to the incremental increase of risk. 


**Profits are not derived from some subtle complicated cleverness of the strategy but from the intrinsic inefficiency in the market that is hidden in plain sight**. 

The most extreme form of linear predictive models is one in which all the coefficients are equal in magnitude (but not necessarily in sign). If we normalize these factors, but turning them into Z scores
$$\tag{1.1} z(i) = (f(i) - mean(f))/std(f))$$

we can predict tomorrow's return $R$ by,
$$\tag{1.2} R = mean(R) - std(R)\sum^n_{i}sign(i)z(i)/n$$

$sign(i)$ is the historical correlation between $f(i)$ and $R$. Mean and std of $R$ correlate to one-day returns and $f$ correlate to various $i$ factors. WQual weighting to all predictors are often superior because they are not affected by accidents of sampling. 

*relative* returns vs *absolute* returns is better. If we use this to rank stocks, and then form a long-sort portfolio by buying stocks in the top decile and shorting in the bottom decile, the average return of the portfolio is often positive. 


If our goal is to jut rank stocks:
combine $f$'s by using rank,
$$\tag{1.3} rank_s = \sum^n_isign(i)rank_s(i)$$

Greenblatt two factor model:
$f(1)$: return on capital
$f(2)$: earnings yield 

No matter how carefully you try to prevent data snooping, it will creep into your model so use *walk-forward testing*.

**Walk forward testing**: 
Used to determine optimal parameters for a trading strat and to determine the robustness of the strat. 
- optimized with in-sample data for a time window in a data series
-  the remaining data is reserved for out of sample testing
-  small portion of the reserved data following the in sample data is tested and the results are recorded
-  time period shifted forward, process repeated

Also called paper trading because we're virtually trading (not using real money) on live markets. 

### Stock splits and dividend adjustments 

Whenever a company has a stock split of $n-1$ split, the stock price will be divided $n$ times. In the backtest, we typically look at just the price series to determine our trading signals, not the market value series of some account. So unless we back adjusted the prices before the ex-date of the split, we will see a sudden drop in price that might trigger wrong trading signals. 

In the same vein, when a company pays cash dividends of $d$ amount, the stock amount will also go down some $d$ amount. That is because if you own that stock before the dividend ex-date, you will get cash (or stock) distributions in your brokerage account so there should be no change in market value. But if not back-adjusted, can lead to trading signal errors. 

Note: price will decrease because (thx u chatty)
- Value Transfer: When a company pays a dividend, it distributes part of its earnings to shareholders. The value of this cash is subtracted from the company's total value. As a result, the company's market capitalization decreases, leading to a proportional drop in its stock price.

- Ex-Dividend Date: The stock price typically drops by the amount of the dividend on the ex-dividend date. This is because new buyers of the stock on or after this date are not entitled to receive the declared dividend. The drop reflects the reduction in value since the dividend has been effectively detached from the stock.

- Market Perception: Sometimes, paying dividends can signal that a company lacks better investment opportunities for its retained earnings. This perception can cause a decrease in the stock price as investors might prefer companies that reinvest earnings into growth opportunities.

  
**Survivorship bias in stock database**
If you are backtesting a stock-trading model you will suffer from survivorship bias if your historical data does not include delisted stocks. 

Extreme case example: If your model asks you to buy the one stock that dropped the most in the previous dat and hold it forever, it will perform poorly because in many cases the company performing the worst will go bankrupt resulting in the 100% loss of the position. 

Survivorship bias is more dangerous to mena-reverting long-only stock strategies than to mean reverting long-short or short-only strategies. This is because this bias tends to *inflate the backtest performance of a long-only strat* that buys low and sells high. It would *deflate* the backtest performance of a short-only strat that first sells high and then buys low. 

Inflation of the long strategy return tends to outweigh the deflation of the short portfolio return. 

**Primary vs. consolidated stock prices**
When you submit a market on close (MOC) or a market on open (MOO) order, it will always be routed to the primary exchange only. 

**MOC** Market-on-Close (MOC) Order: An order to buy or sell a security at the market price as close as possible to the market's closing price. 

**MOO** Market-on-Open (MOO) Order: An order to buy or sell a security at the market price at the opening of the trading day. 

If you have a strategy that relies on MOO or MOC orders, you need the historical prices from the primary exchange to accurately backtest your model. The transaction prices on the next trading day will usually mean revert from hard to achieve outlier prices. 

Similar considerations apply to using high or low prices for strategies. Historical data is usually consolidated highs or lows, not that of the primary exchange. They are often unrepresentative, exaggerated numbers resulting from trades of small sizes on secondary markets.

**Venue dependence of currency quotes**


